# Neural-Network-and-Deep-Learning

-> PROJECT DESCRIPTION

This project is the 1st step into the Deep learning algorithms. After a quick refresher of math in pre-work, this project will walk you through the fundamental concepts of Deep Learning, Packages of Keras and Tensorflow and then basics of Neural Networks.

-> PROJECT OBJECTIVE

1. Get familiar with the Deep Learning jargon and the respective concepts in detail 
2. Understand & appreciate the dynamics behind the Neural Algorithms
3. Build basic Neural Nets for problem-solving
 
-> PROJECT PREREQUISITES
1. Knowledge of Mathematical functions & Linear Algebra
2. Knowledge of Python is very crucial
 
 

-> PROJECT CONTENT
1. NEURAL NETWORKS DECONSTRUCTED FRO SL(CLASSIFICATION) AND INTRO TO TENSORFLOW AND KERAS
    1. Introduction to Perceptron & History of Neural networks
    2. Activation functions
    3. Sigmoid function
    4. ReLU
    5. Tanh
    6. Softmax
    7. Leaky ReLU
    8. Gradient descent
    9. Using Gradient descent to minimize loss function
    10. Vanilla, Stochastic and batch gradient descent
    11. Mini batching
    12. Learning rate and tuning
    13. Learning rate decay
    14. Momentum
    15. Sadle points, Hessians and local furrows
    16. Optimizer functions
    17. SGD optimizer
    18. Adam optimizer
    19. Introduction to Tensor flow
    20. Understanding the computational graph
    21. Using Tensor flow to build a linear regression model
    22. Introduction to Keras
    23. Using Keras to build a simple Neural network
    
2. BUILDING BLOCKS OF NEURAL NETWORKS
    1. Backpropagation and chain rule
    2. Jacobian matrix
    3. Propagation of loss gradient
    4. Fully connected layer
    5. Softmax
    6. Cross-Entropy
    
3. BABBYSITTING THE NEURAL NETWORK
    1. Weight initialization
    2. Problem with zero weights initialization
    3. Xavier initialization
    4. He initialization
    5. Regularization
    6. Batch Normalization
    7. Mini batching
    8. Dropouts
    9. Inverted dropouts
    10. Babysitting the neural network
    11. Hands-on demo for tuning the hyperparameter for Neural networks


PART I consists of industry based problem which can be solved using neural networks as a regressor.

-> DATA DESCRIPTION: The data set contains information on various signal tests performed:
       
        1. Parameters: Various measurable signal parameters.
        2. Signal_Quality: Final signal strength or quality
-> PROJECT OBJECTIVE: The need is to build a regressor which can use these parameters to determine the signal strength or quality [as number].

PART II consists of industry based problem which can be solved using neural networks as a classifier.

-> DATA DESCRIPTION: The data set contains information on various signal tests performed:

        1. Parameters: Various measurable signal parameters.
        2. Signal_Quality: Final signal strength or quality
-> PROJECT OBJECTIVE: The need is to build a classifier which can use these parameters to determine the signal strength or quality [as number].

PART III consists of implementing a clickable GUI which can automate Part I & II of this project.

PART IV consists of building animage classifier using a neural network classifier.

-> DATA DESCRIPTION:

        The SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with the minimal requirement on
        data formatting but comes from a significantly harder, unsolved, real-world problem (recognising digits and numbers in natural scene images).
        SVHN is obtained from house numbers in Google Street View images.
        Where the labels for each of this image are the prominent number in that image i.e. 2,6,7 and 4 respectively.
        The dataset has been provided in the form of h5py files. You can read about this file format here:
        http://docs.h5py.org/en/stable/high/dataset.html
        
-> PROJECT OBJECTIVE: We will build a digit classifier on the SVHN (Street View Housing Number) dataset.
